{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Tesseract OCR para Imagens\n"
      ],
      "metadata": {
        "id": "JldJBfJTPntf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbxhD9HZj3Vb",
        "outputId": "a9ad00ef-f488-4b89-f644-c0f265085ace"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro, vamos instalar as dependências necessárias:"
      ],
      "metadata": {
        "id": "pxVxZiDULynJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgB7-YRDwrXo",
        "outputId": "932d7cdc-a308-40b2-c2cd-7c6148b55482"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpNR8M5dPRKL",
        "outputId": "348029b7-e38a-4e1f-9b3b-db7968a5a50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 3,743 kB of archives.\n",
            "After this operation, 16.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.5 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Fetched 3,743 kB in 2s (1,882 kB/s)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 126308 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.5_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-por\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 856 kB of archives.\n",
            "After this operation, 1,998 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-por all 1:4.00~git30-7274cfa-1.1 [856 kB]\n",
            "Fetched 856 kB in 2s (467 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-por.\n",
            "(Reading database ... 126441 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-por_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-por (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-por (1:4.00~git30-7274cfa-1.1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y tesseract-ocr\n",
        "!apt-get install -y libtesseract-dev\n",
        "!apt-get install -y tesseract-ocr-por"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, podemos carregar a imagem e aplicar o OCR:"
      ],
      "metadata": {
        "id": "KxVd5jNfPpGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Carregando a imagem\n",
        "img = cv2.imread('cnh.jpg')\n",
        "\n",
        "# Check if the image was loaded successfully\n",
        "if img is None:\n",
        "    print(\"Error: Could not load the image. Please check the file path.\")\n",
        "else:\n",
        "    # Convertendo para escala de cinza\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    cv2_imshow(img_gray)\n",
        "\n",
        "    # Aplicando o Tesseract OCR\n",
        "    texto = pytesseract.image_to_string(img_gray, lang='por')\n",
        "    print(texto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYm7uq6hPrT7",
        "outputId": "5d597b04-f749-4a7d-9b58-d431ef68f0f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not load the image. Please check the file path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(img)"
      ],
      "metadata": {
        "id": "5OWNaqvRft1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img_gray)"
      ],
      "metadata": {
        "id": "UJLXsC4ef8jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento e Melhoria de Imagem"
      ],
      "metadata": {
        "id": "0vShrwZ9QLVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando técnicas de thresholding\n",
        "_, img_thresh = cv2.threshold(img_gray, 142, 255, cv2.THRESH_BINARY)\n",
        "cv2_imshow(img_thresh)\n",
        "\n",
        "# Extraindo texto após pré-processamento\n",
        "texto_thresh = pytesseract.image_to_string(img_thresh, lang='por')\n",
        "print(texto_thresh)"
      ],
      "metadata": {
        "id": "kgd5udSDQTyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando o método de Otsu\n",
        "_, img_otsu = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "cv2_imshow(img_otsu)\n",
        "\n",
        "# Extraindo texto após pré-processamento\n",
        "texto_otsu = pytesseract.image_to_string(img_otsu, lang='por')\n",
        "print(texto_otsu)"
      ],
      "metadata": {
        "id": "z7dOtzM7Qe9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando limiarização adaptativa\n",
        "img_adaptive_mean = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 33, 9)\n",
        "cv2_imshow(img_adaptive_mean)\n",
        "\n",
        "# Extraindo texto após pré-processamento\n",
        "texto_adaptive_mean = pytesseract.image_to_string(img_adaptive_mean, lang='por')\n",
        "print(texto_adaptive_mean)\n"
      ],
      "metadata": {
        "id": "D384r9jRQpS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando filtros para remoção de ruído\n",
        "img_median_blur = cv2.medianBlur(img_gray, 3)\n",
        "cv2_imshow(img_median_blur)\n",
        "\n",
        "# Extraindo texto após pré-processamento\n",
        "texto_median_blur = pytesseract.image_to_string(img_median_blur, lang='por')\n",
        "print(texto_median_blur)"
      ],
      "metadata": {
        "id": "ImhEBgpBQysD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analise da extração!"
      ],
      "metadata": {
        "id": "ZURbHqHqLta6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Texto original\n",
        "texto_original = \"\"\"\n",
        "Você não pode colocar um limite\n",
        "em nada. Quanto mais você sonha,\n",
        "mais longe você chega.\n",
        "\n",
        "Michael Phelps\n",
        "\"\"\"\n",
        "\n",
        "# Variáveis que contêm os textos OCR a serem verificados\n",
        "texto_ocr_variants = {\n",
        "    \"texto\": texto,\n",
        "    \"texto_thresh\": texto_thresh,\n",
        "    \"texto_otsu\": texto_otsu,\n",
        "    \"texto_adaptive_mean\": texto_adaptive_mean,\n",
        "    \"texto_median_blur\": texto_median_blur,\n",
        "}\n",
        "\n",
        "def compare_texts(original, ocr_text):\n",
        "    matcher = SequenceMatcher(None, original, ocr_text)\n",
        "    match_ratio = matcher.ratio()\n",
        "    return match_ratio\n",
        "\n",
        "def main():\n",
        "    original_len = len(texto_original)\n",
        "    print(f\"Quantidade de caracteres no texto original: {original_len}\\n\")\n",
        "\n",
        "    for variant_name, ocr_text in texto_ocr_variants.items():\n",
        "        ocr_len = len(ocr_text)\n",
        "        accuracy = compare_texts(texto_original, ocr_text)\n",
        "        accuracy_percentage = accuracy * 100\n",
        "\n",
        "        print(f\"Resultado para {variant_name}:\")\n",
        "        print(f\"Quantidade de caracteres no texto OCR: {ocr_len}\")\n",
        "        print(f\"Percentual de acertos: {accuracy_percentage:.2f}%\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "wyUdU8yBGjHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paddle OCR"
      ],
      "metadata": {
        "id": "yUyhA3NLMFrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddleocr==2.7.3\n",
        "!pip install paddlepaddle==2.6.1"
      ],
      "metadata": {
        "id": "fE4hUJawMN3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from paddleocr import PaddleOCR\n",
        "\n",
        "# Inicializa o objeto PaddleOCR\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
        "\n",
        "# Função para extrair texto OCR de um PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    # Use o método `ocr.ocr()` para extrair texto de uma imagem\n",
        "    extract_ocr = ocr.ocr(pdf_path)  # Removido o argumento `lang`\n",
        "\n",
        "    # Concatene todas as palavras detectadas em uma única string\n",
        "    result = ''\n",
        "    for line in extract_ocr:\n",
        "        for word in line:\n",
        "            result += word[1][0] + ' '  # O índice 0 representa o texto da palavra\n",
        "        result += '\\n'  # Adicione uma nova linha após cada linha de texto\n",
        "    return result\n",
        "\n"
      ],
      "metadata": {
        "id": "r6NbArFEMHi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from utils.AI_response_formatting import extract_fields\n",
        "# from utils.ocr_extraction import OCRProcessor\n",
        "\n",
        "# Caminho para o arquivo PDF\n",
        "pdf_path = \"/content/enel_ficticia.pdf\"\n",
        "\n",
        "# Extrai texto do PDF usando OCR\n",
        "ocr_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# Imprimir os campos extraídos\n",
        "print(ocr_text)"
      ],
      "metadata": {
        "id": "3JHF57kQMZ59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Expressões regulares para encontrar padrões específicos\n",
        "padrao_cpf_cnpj = r\"CPF/ CNPJ:\\s([\\d.-]+)\"\n",
        "padrao_nome_cliente = r\"CPF:\\s([\\w\\s]+)\\s\\d{3}\\.\\d{3}\\.\\d{3}-\\d{2}\"\n",
        "padrao_num_cliente = r\"NDO CLIENTE\\s(\\d+)\"\n",
        "padrao_data_leitura = r\"DataLeitor\\sLeitura\\s(\\d{2}/\\d{2}/\\d{4})\"\n",
        "padrao_data_vencimento = r\"MES/AN\\sVENCIMENT\\sTOTAL\\sA\\sPAGAF\\s(\\d{2}/\\d{4}\\s\\d{2}/\\d{2}/\\d{4})\"\n",
        "padrao_valor_total = r\"R\\$(\\d+,\\d{2})\"\n",
        "padrao_descricao_faturamento = r\"DESCRICAO DO FATURAMENTO(.*?)MENTOS DE MEI\"\n",
        "padrao_referencia_faturamento = r\"Referencia\\s(\\d{2}/\\d{4}\\s\\d{2}/\\d{2}/\\d{4})\"\n",
        "padrao_qr_code = r\"Pague via PIX! Utilize este QR Code\"\n",
        "\n",
        "# Função para extrair informações com base nos padrões de expressão regular\n",
        "def extrair_informacoes(texto, padrao):\n",
        "    match = re.search(padrao, texto)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Extrair informações\n",
        "cpf_cnpj = extrair_informacoes(ocr_text, padrao_cpf_cnpj)\n",
        "nome_cliente = extrair_informacoes(ocr_text, padrao_nome_cliente)\n",
        "num_cliente = extrair_informacoes(ocr_text, padrao_num_cliente)\n",
        "data_vencimento = extrair_informacoes(ocr_text, padrao_data_vencimento)\n",
        "valor_total = extrair_informacoes(ocr_text, padrao_valor_total)\n",
        "referencia_faturamento = extrair_informacoes(ocr_text, padrao_referencia_faturamento)\n",
        "\n",
        "# Verificar se há QR Code presente\n",
        "qr_code_presente = re.search(padrao_qr_code, ocr_text) is not None\n",
        "\n",
        "# Exibir informações extraídas\n",
        "print(\"Nome do Cliente:\", nome_cliente)\n",
        "print(\"CPF/CNPJ:\", cpf_cnpj)\n",
        "print(\"Número do cliente:\", num_cliente)\n",
        "print(\"Data de vencimento:\", data_vencimento)\n",
        "print(\"Valor total:\", valor_total)\n",
        "print(\"Referência do faturamento:\", referencia_faturamento)\n",
        "print(\"QR Code presente:\", qr_code_presente)\n"
      ],
      "metadata": {
        "id": "7ofwomkQQjhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67f6cc79"
      },
      "source": [
        "# Make sure to load the image for PaddleOCR as well, if needed\n",
        "# For example, if you're processing the same image 'cnh.png':\n",
        "# img_paddle = cv2.imread('cnh.png')\n",
        "\n",
        "# If you are processing a PDF file, the PaddleOCR library handles the image loading internally.\n",
        "# Make sure the path to your PDF file is correct.\n",
        "# pdf_path = \"/content/enel_ficticia.pdf\"\n",
        "\n",
        "# If you were trying to use the 'img' variable from the previous section with PaddleOCR,\n",
        "# you would need to ensure 'img' was loaded successfully there."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}